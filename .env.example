# ElevenLabs Configuration
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
ELEVENLABS_VOICE_ID=JBFqnCBsd6RMkjVDRZzb
ELEVENLABS_TTS_MODEL=eleven_multilingual_v2
ELEVENLABS_LANGUAGE=it
ELEVENLABS_STT_MODEL=scribe_v1
ELEVENLABS_STT_LANGUAGE=ita

# Main LLM provider to use
# Options: openai, gemini, groq, openrouter [cloud] or ollama [local]
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_STT_MODEL=gpt-4o-transcribe
OPENAI_STT_LANGUAGE=it

# Google Gemini Configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-pro

# Ollama Configuration (local)
OLLAMA_MODEL=llama3.1:8b
OLLAMA_API_BASE=http://localhost:11434

# OpenRouter Configuration
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=qwen/qwq-32b:free

# groq Configuration
GROQ_API_KEY=your_groq_api_key_here
GROQ_LLM_MODEL=llama-3.1-8b-instant
GROQ_STT_MODEL=whisper-large-v3-turbo
GROQ_STT_LANGUAGE=it

# Fallback models in case the primary model fails
# Comma-separated list of models, e.g.: "gpt-3.5-turbo,ollama/llama3.1:8b"
LLM_FALLBACKS=gpt-3.5-turbo,ollama/llama3.1:8b

# Chat History Configuration
# Maximum number of user-assistant message pairs to keep in the context window
# Higher values provide better context but use more tokens
MAX_HISTORY_MESSAGES=5

# Temperature setting for LLM responses (0.0 to 1.0)
LLM_TEMPERATURE=0.5