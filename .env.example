# ===== speech service configuration =====
# these settings can be overridden with command-line arguments
# TTS options: elevenlabs, kokoro
TTS_PROVIDER=elevenlabs
# STT options: elevenlabs, groq, openai
STT_PROVIDER=elevenlabs
TTS_SPEED=1.0

# ===== llm configuration =====
# main llm provider to use
# options: openai, gemini, groq, openrouter [cloud] or ollama [local]
LLM_PROVIDER=openai
# temperature setting for llm responses (0.0 to 1.0)
LLM_TEMPERATURE=0.5
# fallback models in case the primary model fails
# comma-separated list of models, e.g.: "gpt-3.5-turbo,ollama/llama3.1:8b"
LLM_FALLBACKS=gpt-4o-mini,ollama/llama3.1:8b

# ===== elevenlabs configuration =====
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
ELEVENLABS_VOICE_ID=JBFqnCBsd6RMkjVDRZzb
ELEVENLABS_TTS_MODEL=eleven_multilingual_v2
ELEVENLABS_LANGUAGE=it
ELEVENLABS_STT_MODEL=scribe_v1
ELEVENLABS_STT_LANGUAGE=ita

# ===== kokoro configuration =====
KOKORO_VOICE=im_nicola
KOKORO_LANGUAGE=i

# ===== openai configuration =====
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_LLM_MODEL=gpt-4o-mini
OPENAI_STT_MODEL=gpt-4o-transcribe
OPENAI_STT_LANGUAGE=it

# ===== groq configuration =====
GROQ_API_KEY=your_groq_api_key_here
GROQ_LLM_MODEL=llama-3.1-8b-instant
GROQ_STT_MODEL=whisper-large-v3-turbo
GROQ_STT_LANGUAGE=it

# ===== google gemini configuration =====
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-flash

# ===== ollama configuration (local) =====
OLLAMA_MODEL=llama3.1:8b
OLLAMA_API_BASE=http://localhost:11434

# ===== openrouter configuration =====
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=qwen/qwq-32b:free

# ===== chat history configuration =====
# maximum number of user-assistant message pairs to keep in the context window
# higher values provide better context but use more tokens
MAX_HISTORY_MESSAGES=5